---
layout: post
title: "4장: 검색"
author: 'CSS Dev'
thumbnail: undefined
tags: 
---


이베이는 이 거미들을 충분히 가지고 있었다. 그들은 수천명을 속여먹고 있었다. 그들의 서버에는 쉴 새 없이 많은 활동이 있었고, 끊임없이 침입자가 쏟아져 나왔다. 그러나 한 공격수는 다른 공격수를 앞질렀다. 경매 애그리게이터라고 자칭한 비더즈 엣지는 이베이의 페이지를 정기적으로 기어 다니며 콘텐츠를 추출하고 다른 경매 목록과 함께 이베이의 사이트에 등록했다.

그 유명한 경매 사이트는 과거에 Bider`s Edge를 차단하려고 시도했으나 성공하지 못했다. Whac-A-Mole의 정교한 게임처럼, 그들은 Bider`s Edge 서버의 IP 주소를 제한했지만, 새로운 서버가 있는 프록시 서버에 의해 다시 한번 침해당했다. 기술은 실패했었다. 소송은 그 다음이었다.

이베이는 1999년 12월 소수의 이유를 들어 비더즈 엣지를 상대로 소송을 제기했다. 그것은 법률학자들에게는 "채틀에 대한 침입으로 알려진 고대 무단침입 이론, 기본적으로 물건, 동물, 또는 이 경우에는 서버에 대한 무단침입이나 간섭"을 포함했습니다. 다시 말해서, eBay는 Bider`s Edge가 그들의 서버에 침입했다고 주장했습니다. 그것이 채팅에 대한 불법 침입에 해당하기 위해서, 이베이는 불법 침입자들이 해를 끼치고 있다는 것을 증명해야 했다. 그들은 서버가 부하에 의해 좌굴되고 있다는 것이 그 해악의 증거라고 주장했다.

![image](https://i1.wp.com/css-tricks.com/wp-content/uploads/2020/09/ebay-1999.png?resize=838%2C573&ssl=1)

로널드 M 판사 왜 te는 그 마지막 부분이 매력적이라고 생각했는지. 법정 기록에 "무례한 로봇"이라는 문구가 포함된, 새로운 시대의 가장 이상한 소송들 중 하나에서, 꽤 많은 의견의 일치가 뒤따랐다. 이 로봇들은, "정중한" 로봇들과는 달리, 그들의 사이트에서 스파이더링을 차단하라는 이베이의 요청을 무시하고, 모든 대응책을 회피하려고 시도했다. 그들은 법관의 추정에 의하면 불법 침입자였다. Whyte는 Bider`s Edge가 이베이를 기어다니는 것을 모든 것이 해결될 때까지 중단하라는 명령을 내렸다.

몇 번의 항소와 항소와 항소는 나중에 해결되었다. 입찰자 엣지는 이베이에게 미공개 금액을 지불하고 즉시 문을 닫았다. 이베이는 이 특별한 전투에서 승리했다. 그들은 로봇을 없앴다. 그러나 실제 전쟁은 이미 패배했다. 무례하든 그렇지 않든 간에 로봇들은 이미 이곳에 와 있었다.

스탠포드 대학이 아니었다면, 웹 검색은 사라졌을지도 모른다. 야후, 구글, 익사이드의 탄생지이다. 그것은 첫 번째 검색 엔진을 작동시킨 코드를 실행했던 서버를 실행했다. 야후와 구글의 설립자들은 모두 동문이다. 그러나 검색에서 가장 유명한 선수들 중 많은 수가 컴퓨터 과학 부서에 있지 않았다. 그들은 상징적인 시스템 프로그램에 있었다.

상징적 시스템은 1985년 스탠포드에서 `정보를 표현하고, 처리하고, 행동하는 자연적 시스템과 인공적 시스템의 관계`에 대한 연구로 만들어졌다. 학문 간 접근 방식은 언어학, 수학, 기호학, 심리학, 철학, 컴퓨터 과학 등 여러 분야의 교차점에 뿌리를 두고 있다.

이것들은 20세기 후반의 인공지능 연구의 핵심에서 찾을 수 있는 것과 같은 연구 분야이다. 하지만 이것은 A가 아닙니다.I.는 현대의 스마트 홈 표현에서, 그러나 컴퓨터 과학자들이 컴퓨팅 기술의 미래에 대한 로드맵으로 생각하는 보다 고전적인 개념에서이다. 그것은 인간의 정신을 증강시키는 한 방법으로서의 기계의 이해이다. 그 유사점은 우연이 아니다. 기호학 시스템 프로그램에서 가장 중요한 연구 분야 중 하나는 인공지능이다.

이 프로그램의 동문 중에는 야후의 네 번째 직원인 익사이트와 스리니자 스리니바산의 설립자 몇 명이 포함되어 있다. 그녀의 인공지능 작업은 야심찬 A의 자리를 만들었다.I. 연구실 Cyc는 대학을 졸업했다.

구글의 초기 직원이자 후에 야후의 CEO인 마리사 메이어도 A를 끌어들였다.상징적 시스템 프로그램에서의 I. 연구. 그녀의 획기적인 논문 프로젝트는 자연어 처리를 이용하여 사용자들이 컴퓨터와 간단한 대화를 통해 최상의 항공편을 찾을 수 있도록 도와주었다. "여러분은 사람들이 어떻게 배우고, 어떻게 이치를 따지는지를 보고, 컴퓨터에게 같은 일을 하라고 요구합니다. 이것은 마치 고어 없이 뇌를 연구하는 것과 같습니다,"라고 그녀는 나중에 이 프로그램에 대해 말하곤 했다.

![image](https://i1.wp.com/css-tricks.com/wp-content/uploads/2020/09/mayer-1999.jpg?resize=1024%2C683&ssl=1)

웹에서의 검색은 한 기관에서 한 번에 한 프로그램으로부터 비롯됩니다. 검색 엔진과 관련된 모든 사람들이 그 프로그램을 연구한 것은 아니다. 예를 들어 야후와 구글의 설립자들은 컴퓨터 공학의 대학원생이었다. 그러나 검색의 이데올로기는 인공지능의 전통에 깊이 뿌리를 두고 있다. 결국, 검색의 목표는 뇌에서 질문을 추출하고, 적절한 답을 제공하기 위해 기계를 사용하는 것이다.

야후!에서는 인공지능의 원리가 가이드로 작용했지만, 인간의 시각에 의해 도움을 받을 것이다. 익사이트와 같은 웹 크롤러는 사용자 쿼리의 부담을 떠안고 지능적인 결과를 제공하기 위해 웹 사이트를 프로그래밍 방식으로 매핑하려고 시도한다.

하지만 A가 있는 곳은 구글에 있을 것이다.I.는 명백하게 명시된 목표가 될 것이다. 구글의 역사에 관한 권위 있는 저서인 인 더 플렉스를 쓴 스티븐 레비는 구글을 "인류를 증강하는 인공지능의 꿈을 실현하는 차량"이라고 표현한다. 설립자인 래리 페이지와 세르게이 브린은 A를 언급할 것이다.저는. 계속. 그들은 심지어 첫 기자 회견에서 그 이야기를 꺼냈다.

그 차이는 접근의 문제일 것이다. 5년 동안이나 수색을 지배하게 될 긴장감. 디렉터리 대 크롤러입니다. 기계의 완전성 대 인간의 영향력의 정밀성. 서퍼는 한쪽에 있고 다른 한쪽에 거미가 있습니다. 오직 한 사람만이 살아남을 것이다.

첫번째 거미는 조잡했다. 그들은 어둠 속에서 웹의 가장자리를 찾을 때까지 주위를 더듬었다. 그리고 그들은 집으로 돌아왔다. 때때로 그들은 그들이 기어들어간 웹사이트에 대한 작은 정보들을 수집했다. 처음에 그들은 아무것도 모으지 못했다.

최초의 웹 크롤러 중 하나는 MIT에서 매슈 그레이에 의해 개발되었다. 그는 월드 와이드 유랑자를 이용하여 웹상의 모든 웹사이트를 찾아냈다. 그는 그 사이트들의 내용에 관심이 없었고 단지 그것들을 세고 싶을 뿐이었다. 1993년 여름, 그가 처음으로 크롤러를 보냈을 때, 130이 되었다. 1년 후, 그것은 3,000을 셀 것이다. 1995년에는 그 수가 30,000명에 불과할 정도로 증가하였다.

검색 엔진 사업의 많은 동료들처럼, 그레이는 지식 공유에 헌신하는 컴퓨터 과학의 일부인 정보 검색의 제자였다. 실제로 정보 검색에는 종종 디지털 문서를 기어다니며 프로그래밍 방식으로 콘텐츠를 수집하는 로봇(거미, 크롤러, 방랑자, 웜이라고도 함)이 포함된다. 그런 다음, 검색이 수행될 때마다 모든 문서를 탐색하고 탐색할 필요가 없는 바로 가기인 중앙 집중식 "인덱스"에 구문 분석 및 저장됩니다. 그 지수를 최신으로 유지하는 것은 끊임없는 투쟁이며, 로봇은 경계할 필요가 있다; 다시 나가서 거의 일정한 기초 위에서 정보를 다시 끄집어낸다.

월드 와이드 웹은 문제가 되는 퍼즐을 만들었다. 예측 가능한 문서 집합보다는 이론적으로 무한한 수의 웹사이트가 웹 상에서 살 수 있다. 이러한 것들은 중앙 인덱스에 저장해야 했습니다. 어떻게든 최신 상태로 유지되어야 했습니다. 그리고 가장 중요한 것은, 그 사이트들의 컨텐츠는 누군가가 검색하기를 원하는 모든 것에 즉시, 그리고 몇 초 안에 연결되어야 한다는 것입니다. 그 도전은 일부 정보 검색 연구원과 학자들에게는 거부할 수 없는 것으로 판명되었다. 조나단 플레처 같은 사람들.

전직 졸업생이자 스코틀랜드 스털링 대학의 IT 직원인 플레처는 웹사이트를 찾는 것이 얼마나 어려운지를 좋아하지 않았다. 당시 사람들은 CERN에서 유지 관리하는 WWW 가상 라이브러리나 매일 업데이트한 Mosak의 "What`s New" 목록과 같은 수동 목록에 의존했다. Fletcher는 그것을 다르게 다루길 원했다. "컴퓨팅 과학 학위와 더 나은 방법이 있어야 한다는 생각으로 저는 저를 찾아갈 무언가를 쓰기로 결심했습니다."

1993년 그는 검색 가능한 인덱스의 초기 사례 중 하나인 점프 스테이션을 만들었다. 그의 크롤러는 가능한 한 많은 링크를 따라 나가서 검색 가능한 중앙 집중화된 데이터베이스로 가져왔습니다. 그러면 다시 시작하겠죠. 웹의 무한한 광대함 문제를 해결하기 위해, Fletcher는 각 웹 페이지의 제목과 일부 메타데이터만 탐색하는 것으로 시작했다. 이로 인해 그의 인덱스는 상대적으로 작았지만 페이지 제목에 대한 검색도 제한되었다.

플레처는 혼자가 아니었다. 몇 달 동안 땡땡이 친 후, 웹 크롤러는 1994년 4월 워싱턴 대학에서 출범했다. 그것은 전체 웹 페이지를 탐색하여 검색 가능하게 만든 최초의 검색 엔진이라는 특징을 가지고 있다. 그 해 11월까지 웹크롤러는 백만 건의 질의를 제공하였다. 카네기 멜론에서, 마이클 모들린은 자신의 거미 기반 검색 엔진 변종을 출시했는데, 이것은 늑대 거미인 라이코스의 라틴어 번역에서 따온 것이다. 1995년에는 백만 개 이상의 웹 페이지를 인덱싱하였다.

![image](https://i1.wp.com/css-tricks.com/wp-content/uploads/2020/09/webcrawler-1996.png?resize=830%2C600&ssl=1)

검색은 대학에 오래 머물지 않았습니다. 검색 엔진에는 완벽한 사이트를 찾는 길찾기 웹 사용자들에게 독특한 유틸리티가 있었다. 많은 사용자들이 검색 엔진에서 웹 세션을 시작했습니다. 새로운 웹 사용자를 위한 최고의 브라우저인 Netscape Navigator는 사용자를 그들의 홈페이지의 검색 엔진에 직접 연결했다. 넷스케이프에 이름을 올린다는 것은 눈알을 찌르는 것을 의미했다. 그리고 눈알은 수익성이 좋은 광고 계약을 의미했다.

1990년대 후반에는 다수의 주요 업체들이 검색엔진 시장에 진입했다. 처음에 유료 검색 옵션인 InfoSeek은 디즈니에 의해 선택되었고, 곧 넷스케이프의 기본 검색 엔진이 되었다. AOL은 웹에서 경쟁력을 유지하기 위한 과감한 전략의 일환으로 Web Crawler를 급습하여 구입했습니다. 라이코스는 그것을 완전히 상업적인 기업으로 변모시킨 벤처 투자가에 의해 구입되었다.

스탠포드 대학 동문들이 시작한 또 다른 크롤러이자 검색엔진 게임의 떠오르는 스타인 Excite.com은 출시한지 얼마 되지 않아 300만 달러를 제공받았다. 그것의 여섯 명의 공동 설립자들은 두 명의 소파, 한 사람, 한 사람, 그리고 밤새도록 그것을 이야기했습니다. 그들은 그 제품에 충실하고 새로운 CEO를 영입하기로 결정했다. 더 많은 수백만 달러를 벌 수 있을 것이다.

![image](https://i1.wp.com/css-tricks.com/wp-content/uploads/2020/09/excite-1996.png?resize=838%2C573&ssl=1)

AltaVista는 이미 1995년 말에 게임에 조금 늦었지만 디지털 장비 코퍼레이션에 의해 만들어졌다. 처음에는 DEC 컴퓨터의 처리 능력을 입증하기 위해 제작되었다. 그들은 그들의 멀티스레드 크롤러가 경쟁사들보다 훨씬 더 빠른 속도로 웹사이트를 인덱싱할 수 있다는 것을 재빨리 깨달았다. AltaVista는 한 연구원이 "거미떼"라고 일컫는 크롤러를 한 번에 수천 개의 사이트를 인덱싱하기 위해 정기적으로 배포했습니다.

그 결과, AltaVista는 거의 1,000만 개의 웹 페이지를 시작할 때 사실상 전체 웹을 인덱싱할 수 있었다. 이듬해인 1996년에는 1억이 넘는 지수를 기록하게 될 것입니다. 시스템의 효율성과 성능 덕분에 AltaVista는 확장성 문제를 해결할 수 있었습니다. 일부 이전 회사들과는 달리, 그들은 웹사이트의 전체 콘텐츠를 검색할 수 있게 만들 수 있었고, 그들은 색인을 업데이트하는 데 수개월이 걸릴 수 있는 초기 경쟁사들보다 훨씬 빠른 속도로 몇 주마다 사이트를 다시 탐색했다. 그들은 웹 크롤러의 깊이와 범위에 대한 표준을 정했다.

![image](https://i2.wp.com/css-tricks.com/wp-content/uploads/2020/09/altavista-1996.png?resize=838%2C573&ssl=1)

완전히 안정되지 않은 AltaVista는 자연어 처리, 번역 도구 및 다국어 검색을 실험하면서 검색 엔진을 혁신의 도구로 사용했습니다. 그들은 종종 시대를 앞서나가며, 몇 년 전부터 비디오와 이미지 검색을 제공했는데, 이는 예상된 기능이 될 것이다.

그 열기에 휩쓸리지 않았던 거미들은 따라갈 수가 없었다. 최초의 검색엔진을 보유한 대학들은 대학과 관련도 없는 트래픽으로 인해 인터넷 연결이 비대해지는 것을 전혀 달가워하지 않았다. 대부분의 대학들은 Jumpstation과 같은 최초의 실험적인 검색 엔진을 강제로 종료시켰다. 스탠포드 대학만 빼면요

기술 혁신과 함께 스탠포드의 역사는 20세기 후반부터 시작된다. 그 당시 대학은 2급 기관이 되기 직전까지 비틀거리고 있었다. 그들은 동부 연안의 경쟁자들에게 유리한 계약과 유리한 계약을 잃고 있었다. 하버드와 MIT는 제2차 세계 대전의 여파로 연구 시설의 현장이 되었다. 스탠포드가 뒤쳐지고 있었다.

1951년, 그들의 하향 궤도를 역진하기 위해 프레데릭 테르만 공대 학장은 팔로 알토 시와 계약을 맺었다. 스탠포드 대학교는 캘리포니아의 신생 기업들이 이용할 수 있는 새로운 산업단지에 700에이커의 부지를 추가하기로 합의했다. 스탠포드는 에너지 혁신에 근접할 것이다. 그곳으로 이전하기로 결정한 기업은 제품 개발에 사용할 수 있도록 스탠포드 학생 단체에 독특한 접근 권한을 갖게 될 것입니다. 그리고 팔로 알토 시는 새로운 세금이 유입될 것이다.

휴렛패커드는 처음 입주한 회사들 중 하나였다. 그들은 곧 실리콘 밸리로 알려질 컴퓨팅 중심 산업의 새로운 시대를 맞이했다. 스탠포드 연구단지(나중에 스탠포드 산업단지로 개칭)는 빠른 성공과 실험의 시기에 결국 제록스를 유치하게 된다. 페이스북은 초창기 시절을 그곳에서 보내게 될 것이고, 그렇게 될 것이다. 그 중심에는 스탠포드가 있었다.

그 연구단지는 대학을 침체기의 하나에서 기업가정신과 최첨단 기술의 현장으로 변화시켰다. 그것은 그들을 기술 산업의 중심에 놓았습니다. 스탠포드는 인터넷과 월드 와이드 웹을 포함한 20세기 후반의 중요한 기술 개발에 논리학적으로나 재정적으로나 자신을 포함시킬 것이다.

그러므로 야후!의 잠재적인 성공은 간과되지 않았다.

Jerry Yang과 David Filo는 Yahoo!에서 일하지 않기로 되어 있었다. 하지만 그들은 함께 일하기로 되어 있었다. 그들은 수년 전에 만났는데, 데이비드가 스탠포드 컴퓨터 과학 프로그램에서 제리의 조교였다. Yang은 마침내 Filo에 대학원생으로 합류했고, 강한 유대감을 형성한 후, 곧 함께 프로젝트를 진행한다는 것을 알게 되었다.

그들이 박사과제를 통해 일을 시작하기 위해 대학 트레일러에 몸을 쑤셔넣으면서, 그들의 관계는 양씨가 종종 완벽하게 균형잡힌 것으로 묘사한 것이 된다. "우리는 서로에게 매우 관대하지만, 다른 모든 것에 대해서는 매우 비판적입니다. 우리는 둘 다 매우 고집불통이지만, 우리가 어디로 가야 하는지 이해하는 것에 관해서는 아주 완고하지 않습니다. 서로 필요한 공간을 제공하면서도 필요할 때 서로 돕습니다.

1994년 필로는 양에게 웹을 보여주었다. 단 한순간, 그들의 초점은 바뀌었다. 그들은 의도한 컴퓨터 과학 논문을 옆으로 밀어서, 월드 와이드 웹의 깊은 곳에 몰두함으로써 미루었다. 며칠은 웹서핑과 거래 링크의 달로 바뀐 주들로 바뀌었다. 두 사람은 결국 스탠포드 인터넷 연결에서 호스팅되는 웹사이트인 한 곳에 그들의 목록을 결합하기로 결정했다. 그것은 제리와 데이빗의 월드 와이드 웹 가이드라고 불렸고, 처음에는 1993년에 스탠포드 학생들에게, 그리고 다음에는 1994년 1월에 세계로 출시되었다. 그 이름이 눈에 띄지 않는 만큼, 그 아이디어는 다른 친구들과 공유되면서 시작되었다.

제리와 데이빗 가이드는 디렉토리였다. CERN에서 시작된 가상 라이브러리와 마찬가지로 Yang과 Filo는 웹 사이트를 다양한 범주로 구성했습니다. 이 분류들 중 일부는 이상하거나 거창한 이름을 가지고 있었다. 다른 것들은 당신이 기대했던 것과 똑같았다. 하나의 범주가 너무 커지면, 그들은 그것을 나누었다. 그것은 임시적이고 서툴렀지만 매력이 없는 것은 아니었다. 그들의 분류를 통해, 양씨와 필로는 그들의 사이트에 개성을 부여했다. 그들의 성격. 나중에 양용은은 이것을 "야후의 목소리"라고 불렀다.

이 음성은 사이트의 원래 이름에서 알 수 있듯이 웹의 새로운 사용자를 위한 가이드가 되었습니다. 그들의 웹 크롤링 경쟁자들은 한 번에 수백만 개의 사이트를 인덱싱하는 기술에 훨씬 더 능숙했다. Yang과 Filo의 사이트는 웹의 작은 부분집합만을 특징으로 한다. 하지만 그것은 적어도 그들의 추정으로는 웹이 제공하는 것 중 최고였습니다. 멋진 거미줄이었어 또한 이전보다 훨씬 더 쉽게 탐색할 수 있는 웹이었습니다.

![image](https://i1.wp.com/css-tricks.com/wp-content/uploads/2020/09/yang-filo.jpeg?resize=675%2C455&ssl=1)

1994년 말, Yang과 Filo는 그들의 사이트를 Yahoo!(Yet Another Hierarchical Officious Oracle의 어색한 강제 약어)로 이름을 바꾸었다. 그때까지, 그들은 하루에 거의 10만 건을 얻고 있었고, 그 과정에서 때때로 일시적으로 스탠포드의 인터넷을 다운시키기도 했다. 대부분의 다른 대학들은 그 사이트를 폐쇄하고 그들에게 다시 일하라고 말했을 것이다. 하지만 스탠포드는 아니에요. 스탠포드는 이와 같은 캠퍼스 사업 준비를 위해 수십 년을 보냈습니다. 그들은 서버를 계속 가동시키고, 그것의 창조자들이 실리콘 밸리에 그들만의 길을 걸도록 격려했다.

1994년 내내 넷스케이프는 야후를 브라우저에 포함시켰다. 야후와 직접 연결된 "Net Directory"라는 레이블이 붙은 도구 모음에 버튼이 있었다. 이 사이트의 미래를 믿고 있던 마크 안드레센은 넷스케이프의 서버에 그들의 웹사이트를 호스팅하기로 합의했다.

![image](https://i2.wp.com/css-tricks.com/wp-content/uploads/2020/09/yahoo-1994.jpg?resize=648%2C432&ssl=1)

양 회장과 필로는 소매를 걷어붙이고 투자자들과 대화를 시작했다. 오래 걸리지 않을 거예요. 1996년 봄, 그들은 새로운 CEO를 갖게 되고 그들의 우아한 호스트인 넷스케이프마저 능가하는 그들 자신의 최고 기업공개(IPO)를 갖게 될 것이다. 그때까지, 그들은 큰 차이로 웹상에서 가장 인기 있는 여행지가 되었다.

그동안 웹은 두 친구가 서로 링크를 주고받는 것을 훨씬 뛰어넘어 성장했다. 그들은 수만 개의 부지를 분류할 수 있었지만, 수십만 개의 부지를 더 기어 다닐 수 있었다. 한 기자는 "나는 제리 양이 모던타임즈의 찰리 채플린으로 묘사한다"며 "속도만 늘어나는 새로운 작품의 끝없는 흐름에 직면했다"고 설명했다. 사이트를 구성하는 일은 다른 사람에게 맡겨야 할 것이다. 양용은과 필로는 스탠포드 대학 동문 중 몇 년 전 일본에서 함께 유학하면서 만난 적이 있는 사람으로서 상징적인 시스템 프로그램을 졸업한 스리니자 스리니바산에서 도움을 받았다. 야후!의 초창기 신입사원들 중 많은 사람들은 항상 "야후"로 끝나는 약간 터무니없는 직함을 받았다. Yang과 Filo는 Chief Yahoos에 의해 갔다. 스리니바산의 직함은 온톨로지 야후였다.

그것은 고의적이고 정확한 직책이며, 우연히 뽑힌 것이 아니다. 온톨로지(Ontology)는 존재에 대한 연구이며, 세계를 그 구성요소로 나누기 위한 시도이다. 역사와 세계를 통틀어 많은 전통에서 나타났지만, 그것은 소크라테스의 추종자들, 플라톤의 저작, 그리고 나중에 아리스토텔레스가 쓴 획기적인 본문인 형이상학과 가장 밀접하게 연관되어 있다. 온톨로지는 "무엇이 존재하는가?"라는 질문을 던지며, 그것을 존재와 본질에 대한 이데올로기를 구성하기 위한 사고 실험으로 사용한다.

컴퓨터가 존재하게 되면서 온톨로지는 인공지능 분야에서 새로운 의미를 찾았다. 그것은 기계가 세상을 보는 데 필요한 보다 공식적인 계층적 분류에 맞게 조정되었습니다. 세상을 생각하는 데 말이죠. 온톨로지(Ontology)는 지능형 기계가 사물을 범주로 분류하고 지식을 공유하는 방법을 설명하는 근본적인 방법이 되었습니다.

형이상학과 컴퓨터 과학의 온톨로지에 대한 뒤죽박죽의 정의는 스리니자 스리니바산에게 스탠포드 대학 시절부터 친숙했을 것이다. 그녀의 연구에서 철학과 인공지능의 결합은 그녀에게 계층적 분류에 대한 독특한 관점을 주었다. 이 경험은 그녀가 대학 졸업 후 컴퓨터 상식을 가르치기 위해 과감한 프로젝트를 가진 인공지능 연구실인 Cyc Project에서 자신의 첫 직장으로 데려온 경험이었다.

![image](https://i0.wp.com/css-tricks.com/wp-content/uploads/2020/09/srinija-srinivasan-1.png?resize=800%2C600&ssl=1)

야후에서, 그녀의 임무는 그만큼 대담했다. 누군가가 사이트에서 무언가를 찾을 때, 그들은 관련 결과의 임의의 목록을 되돌리고 싶지 않았다. 그들은 그들이 실제로 생각하고 있는 결과를 원했지만, 어떻게 묘사해야 할지 잘 알지 못했습니다. 야후!는 몇 초 만에 사용자들이 진정으로 원하는 것이 무엇인지 알아내야 했다. 인공지능 분야에서의 그녀의 연구처럼, 스리니바산은 야후!에게 질의에 대해 어떻게 생각하고 올바른 결과를 추론하는지를 가르쳐야 했다.

그러기 위해서, 그녀는 제리와 데이빗에 의해 확립된 관점을 잃지 않고 야후의 목소리를 수십 개의 카테고리와 하위 카테고리의 수천 개의 더 많은 웹사이트로 확장할 필요가 있을 것이다. 그녀는 그 관점을 확장시킬 필요가 있을 것이다. "이것은 형식적인 파일 보관 연습이 아닙니다. 이것은 존재의 본질을 규정하는 것입니다,"라고 그녀는 자신의 프로젝트에 대해 말한 적이 있습니다. "범주와 분류는 우리 세계관의 기본입니다."

일정한 속도로, 그녀는 인간 경험의 온톨로지를 그 사이트에 매핑했다. 그녀는 사이트의 크리에이터로부터 물려받은 임시 범주를 세분화하여 보다 구체적이고 찾을 수 있는 인덱스로 재구성하기 시작했다. 그녀는 새로운 범주를 만들고 오래된 범주를 파괴했다. 그녀는 기존의 과목들을 새롭고 더 정확한 과목들로 세분화했다. 그녀는 결과를 여러 범주 안에서 살 수 있도록 교차 연결시키기 시작했습니다. 몇 달 만에 그녀는 새로운 계층구조로 사이트를 정비했다.

그러나 그 계층적 온톨로지는 단지 지침일 뿐이었다. 야후가 그 동안 고용했던 50여 명의 컨텐츠 매니저들에게 야후!의 확장의 강점은 있었다. 그들은 서퍼로 알려져 있었다. 그들의 일은 웹 서핑을 하고 그것을 정리하는 것이었다.

각 서퍼는 야후!의 방법론에서 지도를 받았지만 놀라운 편집의 자유를 얻었다. 그들은 자신들의 관심사를 가지고 디렉토리를 재배하고, 웹사이트와 그들이 어디에 속해 있는지 꼼꼼하게 검토했다. 각각의 결정은 힘들 수 있고, 도중에 잘못된 조치와 잘못 분류된 항목들이 있었다. 그러나 개인 개성이 계층적 선택을 지시하도록 허용함으로써 야후는 목소리를 유지했다.

그들은 가능한 한 많은 사이트를 모았고, 매일 수백 개의 사이트를 추가했다. 야후 서퍼들은 그들의 사이트 방문자들에게 웹상의 모든 것을 공개하지 않았다. 그들은 그들에게 무엇이 멋진지 보여주었다. 그것은 웹이 무엇을 할 수 있는지를 처음으로 파악하는 사용자들에게 모든 것을 의미했습니다.

1995년 말에 야후 직원들은 그들의 교통 상황을 예의 주시하고 있었다. 콘솔 주위에 옹기종기 모여 있는 직원들은 방문객 감소분을 찾기 위해 몇 번이고 로그를 확인하곤 했다. 야후!는 수년 동안 넷스케이프에서 "인터넷 디렉터리" 버튼의 대상이었다. 그것은 그들의 성장과 교통의 원천이었다. 넷스케이프는 마지막 순간에 (그리고 무작위로 보이는) 야후를 탈퇴하기로 결정을 내렸고, 야후를 블록의 새로운 아이들로 대체했다. Excite.com 최상의 시나리오: 관리 가능한 하락. 최악의 경우: 야후!의 소멸.

하지만 한 방울도 오지 않았다. 하루가 가고 또 가고 또 가고 또 하루가 가고. 그리고 일주일이요. 그리고 몇 주. 그리고 야후는 가장 인기 있는 웹사이트로 남아있었다. 야후!의 첫 번째 직원 중 한 명인 팀 브래디는 그 순간을 진심으로 놀라움으로 표현한다. "마루가 이틀 만에 뽑힌 것 같았고, 우리는 여전히 서 있었습니다. 우리는 주위를 둘러보며 여러 가지 방법으로 무너지기를 기다리고 있었다. 그리고 우리는 이제 독립한 것 같아요."

넷스케이프는 그들의 디렉터리 버튼을 오랫동안 독점적으로 유지하지 않을 것이다. 1996년에는 다른 검색 엔진을 브라우저의 "검색" 기능에 나열하는 것을 허용하기 시작했다. 사용자가 단추를 클릭하면 옵션 드롭다운이 유료로 나타납니다. 야후는 다시 다운로드에 가입했다. 그들은 Lycos, InfoSeek, Excit, AltaVista 등 4개의 다른 검색 엔진과 함께 했다.

그 무렵 야후는 독보적인 선두주자였다. 그것은 그것의 퍼스트 무버 이점을 성공적인 IPO와 새로운 투자 유입에 의해 강화된 새로운 전략으로 바꾸었다. 야후!는 단순한 검색 엔진 그 이상이기를 원했다. 그들의 사이트의 변화는 결국 포털이라고 불리게 될 것이다. 그것은 웹상의 모든 가능한 요구를 위한 중심 위치였다. 야후는 많은 제품 확장과 공격적인 인수를 통해 새로운 브랜드의 디지털 제품을 출시했다. 이메일을 보내야 합니까? 야후를 사용해 보세요! 메일. 웹 사이트 만들기를 원하십니까? 야후가 있어! 지구 도시들. 일정을 추적하시겠습니까? 야후를 사용하세요! 달력. 그리고 그 리스트는 계속되었다.

![image](https://i1.wp.com/css-tricks.com/wp-content/uploads/2020/09/yahoo-1996.png?resize=838%2C573&ssl=1)

경쟁자들이 2번 슬롯의 공백을 메웠다. 1996년 4월, 야후, 라이코스, 익사이드는 모두 치솟는 주가에 상장되었다. 인포섹은 불과 몇 달 후에 그들의 첫 번째 제안을 받았다. 빅딜은 미래에 대한 과감한 청사진과 충돌했다. 익사이트는 더 큰 웹 조각에서 더 정확한 검색 결과를 얻어 야후!의 보다 활기찬 대안으로 자리잡기 시작했다. 한편, 라이코스는 야후에게 횡재했던 포털 기반의 게임 계획을 뒤쫓는 초기 성공을 가져다 준 검색엔진을 거의 다 갖추고 있었다.

언론은 이 대회를 단일 전략으로 수백만 달러가 쏟아지는 웹 역사의 덧없는 순간인 포털 전쟁이라고 칭했다. 웹 서퍼를 위한 최대 규모의 중앙 집중화된 포털이 될 수 있습니다. 사용자에게 웹에서 목적지를 제공하는 모든 서비스는 경기장 안으로 던져졌다. 웹의 미래(그리고 10억 달러 규모의 광고 산업)가 위태로웠다.

하지만 어떤 면에서는 포털 전쟁이 시작되기 전에 끝났다고 볼 수 있습니다. 익사이트가 인터넷 서비스 공급업체인 @Home과의 거대한 합병을 발표했을 때, 모두가 이것이 현명한 조치라고 생각하는 것은 아니었다. "AOL과 야후!가 이미 선두를 달리고 있었다"고 한 투자자이자 케이블 업계의 베테랑은 "3위 포털을 위한 여지가 없었다"고 언급했다. AOL은 Yahoo!의 뒤를 밟으며 #2 슬롯에 진출할 수 있는 충분한 근육과 영향력을 가지고 있었다. 다른 모든 사람들은 골리앗과 함께 서로 싸워야 할 것이다. 아무도 그것을 해낼 수 없었다.

대부분의 검색 엔진은 시장 지배력 확보에 어려움을 겪으면서 검색의 방향을 잃었습니다. 대부분의 경우 전자 메일, 주식 티켓 및 스포츠 피드 옆에 2등급 검색 엔진을 사용하여 물건을 찾을 수 있습니다. 자주 검색하거나 잘 검색되지 않을 뿐이었습니다. 스탠포드의 또 다른 검색엔진이 단 하나의 검색창과 두 개의 버튼, 즉 밝고 다양한 색깔의 로고가 위에 도배된 채 출시되었을 때, 그것은 매우 신선했던 이유이다.

구글이 출시된 지 몇 년 후, 구글은 가장 인기 있는 사이트들의 최종 리스트에 올랐다. 2002년 PBS 뉴스워어와의 인터뷰에서 공동 창업자인 래리 페이지는 그들의 장기적인 비전을 설명했다. "실제로, 궁극적인 검색엔진은 여러분이 질의어를 입력할 때 정확히 무엇을 원하는지 이해할 수 있고, 그것이 여러분에게 정확한 정보를 제공해 줄 것입니다. 컴퓨터 과학에서 우리는 인공지능이라고 부릅니다."

구글은 어디에서든 시작할 수 있었다. 무슨 일이든 시작할 수 있었어요. 한 직원은 "우리는 검색에 별로 관심이 없다"는 말을 들은 사이트 설립자들과의 초기 대화를 회상한다. 우리는 A.I.를 만들고 있습니다." 구글의 크리에이터인 래리 페이지와 세르게이 브린은 웹에서 가장 훌륭한 검색엔진을 만들려고 하지 않았습니다. 그들은 웹에서 가장 지능적인 웹사이트를 만들려고 시도하고 있었다. 검색은 가장 논리적인 시작점에 불과했습니다.

정확하지 않고 어설픈 1996년의 스파이더 기반 검색 엔진은 힘든 싸움을 직면했다. AltaVista는 웹 전체, 수천만 개의 웹 페이지를 인덱싱할 수 있음을 증명했다. 그러나 몇 가지 부울 논리 명령을 사용하지 않는 한 컴퓨터가 올바른 결과를 반환하도록 하는 것은 어렵습니다. 페이지 씨의 말에 따르면, 로봇들은 아직 "정확히 당신이 원하는 것"을 추론할 준비가 되어 있지 않았습니다.

야후는 서퍼들로 이 기술의 틈새를 메웠다. 서퍼들은 알고리즘에 의존하지 않고 그들의 디렉토리를 하나하나 설계하면서 컴퓨터 과정을 수정할 수 있었다. 야후!는 특정한 종류의 온라인 시크함의 중재자가 되었다; 맛 만드는 사람들은 정보화 시대를 위해 다시 상상했다. 야후 서퍼들은 몇 년 동안 지속될 트렌드를 설정했다. 당신의 사이트는 그들의 손에 의해 죽거나 살 것이다. 기계가 스스로 그 일을 할 수 없었습니다. 만약 당신이 당신의 기계가 지능적이기를 원한다면, 당신은 그들을 인도할 사람들이 필요했다.

페이지와 브린은 동의하지 않았다. 그들은 컴퓨터가 그 문제를 아주 잘 처리할 수 있다고 믿었다. 그리고 그들은 그것을 증명하는 것을 목표로 했다.

그 흔들리지 않는 자신감은 구글의 "악이 되지 말라"는 모토보다 훨씬 더 많은 것을 정의하게 될 것이다. 초기에는 웹을 위한 다른 미래를 설계하는 데 레이저로 초점을 맞추면 현재의 일상적인 작업에는 눈이 멀게 된다. 한 번이 아니라 두 번, 수십만 달러를 받고 회사에 지불한 수표가 책상 서랍이나 차 트렁크에 남겨졌다. 누군가가 마침내 그것들을 입금할 시간을 낼 때까지 말이다. 그리고 그들은 종종 다르게 행동했다. 예를 들어, 구글의 사무실은 대학 기숙사를 시뮬레이션하기 위해 지어졌는데, 이는 창업자들이 큰 아이디어에 가장 도움이 된다고 느끼는 환경이다.

구글은 결국 가장 정교하고 복잡한 (그리고 거의 틀림없이 침습적인) 광고 메커니즘에 힘입은 그들 자신의 디자인의 정교하고 세계적 수준의 인프라 위에 문자 그대로의 제국을 건설할 것이다. 구글만큼 규모가 큰 기업은 거의 없다. 이것은 다른 사람들과 마찬가지로 스탠포드에서 시작되었습니다.

가장 유명한 인공지능 전문가들 사이에서도 컴퓨터 과학자이자 스탠포드 교수인 테리 위노그라드가 군중 속에서 눈에 띈다. 그는 컴퓨터 공학부의 대학원생이었을 때 래리 페이지의 조언자이자 조언자였다. Winograd는 종종 페이지로부터 "우주 테더 또는 태양 연"과 관련된 논문 프로젝트를 위해 받을 비정통적이고 독특한 제안들을 떠올렸다. "그것은 컴퓨터 과학보다 공상 과학이었다"라고 그는 나중에 말하곤 했다.

그러나 상상력의 모든 환상적인 비행을 위해 페이지는 항상 월드 와이드 웹으로 돌아왔다. 그는 그것의 하이퍼링크 구조가 매혹적이라는 것을 알았다. 웹 성공의 중요한 요소인 그것의 일방적인 링크는 새로운 웹사이트의 엄청난 확산으로 이어졌다. 페이지가 처음 웹을 보기 시작한 1996년에는 매주 수만 개의 사이트가 추가되었다. 웹의 마스터 스트로크는 한 방향으로만 이동하는 링크를 활성화하는 것이었다. 이로 인해 웹이 분산될 수 있었지만 중앙 데이터베이스 추적 링크가 없으면 특정 웹 페이지에 연결된 모든 사이트의 목록을 수집하는 것이 거의 불가능했다. 페이지는 누가 누구와 연결하는지 보여주는 그래프를 만들고 싶어했습니다. 관련 웹 사이트를 상호 참조하는 데 사용할 수 있는 색인입니다.

페이지는 하이퍼링크가 학술 인용문과 디지털 아날로그임을 이해했다. 특정 학술 논문의 가치를 나타내는 핵심 지표는 인용된 횟수이다. (다른 고품질 문서에 의해) 논문이 자주 인용되는 경우, 논문의 신뢰성을 보증하는 것이 더 쉽다. 웹도 같은 방식으로 작동합니다. 사이트가 자주(백링크라고 하는)에 연결될수록 신뢰성과 정확성이 높아집니다.

이론적으로 웹 사이트에 연결된 다른 모든 웹 사이트를 추가하여 웹 사이트의 가치를 결정할 수 있습니다. 그건 한 겹밖에 안 돼요. 100개의 사이트가 다시 연결되어 있지만 각 사이트가 한 번만 연결된 경우 이는 각각 100번 연결된 5개의 사이트가 사용자에게 다시 연결된 경우보다 훨씬 가치가 떨어집니다. 그래서 단순히 얼마나 많은 링크를 가지고 있느냐가 아니라 그 링크들의 질입니다. 백링크를 기준으로 이러한 치수와 집계 사이트를 모두 사용하는 경우 매우 빠르게 품질별로 정렬된 사이트 목록을 구성할 수 있습니다.

존 배텔은 구글 스토리인 검색의 리텔링에서 페이지가 직면한 기술적 문제를 설명한다.

> 페이지는 페이지에 대한 링크 개수가 해당 페이지의 순위를 안내하는 데 유용하다는 것을 깨달았습니다. 그는 또한 각 링크들이 그것의 원본 페이지의 링크 수를 바탕으로 자체적인 순위가 필요하다고 보았다. 그러나 이러한 접근 방식은 어렵고 재귀적인 수학적 과제를 낳습니다. 특정 페이지의 링크를 셀 뿐만 아니라 링크에 연결된 링크도 셀 수 있어야 합니다. 수학은 꽤 빨리 복잡해진다.

다행히도, 페이지는 이미 수학 신동 하나를 알고 있었다. 세르게이 브린은 스탠포드 컴퓨터 과학부에서 박사과정을 시작하기 전에 여러 번 그의 탁월함을 세계에 증명해 보였다. 브린과 페이지는 여러 번 서로 엇갈린 관계를 맺었는데, 이 관계는 바위 위에서 시작되었지만 상호 존중으로 발전했다. 페이지 아이디어의 중심에 있는 수학적 퍼즐은 브린이 포기하기에는 너무 유혹적이었다.

그는 해결책을 강구해야 했다. 그는 나중에 "기본적으로 우리는 수억 개의 변수를 가진 웹 전체를 큰 방정식으로 변환한다"며 "모든 웹 페이지의 페이지 순위와 링크인 수십억 개의 용어"라고 설명했습니다. 그리고 우리는 그 방정식을 풀 수 있습니다." 처음 웹 크롤러를 개발한 구글의 3번째 공동 창업자에 대해 거의 이야기하지 않았던 스콧 하산은 구글의 알고리즘을 "웹을 거꾸로 뒤집기 위한 시도"라고 설명하면서 이를 좀 더 간결하게 요약했다.

결과는 웹 페이지가 아닌 Larry Page와 같이 PageRank였습니다. 브린, 페이지, 하산은 특정 웹 페이지의 품질을 결정하기 위해 사이트의 백링크를 추적할 수 있는 알고리즘을 개발했다. 사이트 백링크의 가치가 높을수록 순위가 상승했습니다. 그들은 많은 다른 사람들이 무엇을 놓쳤는지 알아냈다. 시스템을 올바른 소스(백링크)로 교육하면 놀라운 결과를 얻을 수 있습니다.

그 후에야 그들은 검색 엔진에 페이지랭크가 가장 적합하다는 것을 깨달았을 때 검색 질의에 순위를 매기기 시작했다. 그들은 그들의 검색 엔진을 구글이라고 불렀다. 그것은 1996년 8월에 스탠포드 인터넷 연결로 출시되었다.

![image](https://i1.wp.com/css-tricks.com/wp-content/uploads/2020/09/google-1997.png?resize=1376%2C758&ssl=1)

구글은 초기부터 온라인 검색을 괴롭혔던 관련 문제를 해결했다. Lycos, AltaVista 및 Excit과 같은 크롤러는 특정 검색과 일치하는 웹 페이지 목록을 제공할 수 있었습니다. 그들은 단지 그것들을 제대로 분류할 수 없었기 때문에, 당신은 당신이 원하는 결과를 찾기 위해 땅을 파야만 했다. 구글의 순위는 즉시 관련이 있었다. 검색의 첫 페이지에는 일반적으로 필요한 항목이 있습니다. 그들은 결과에 너무 자신만만해서 사용자들을 검색하기 위해 첫 번째 결과로 직접 데려다 주는 "I`m Feeling Lucky" 버튼을 추가했다.

초기 구글의 성장은 야후와 다르지 않았다. 그들은 입소문을 타고 친구에서 친구 사이까지 퍼져나갔다. 1997년까지 그들은 스탠포드 네트워크에 부담을 줄 정도로 성장했는데, 양씨와 필로가 불과 2년 전에 했던 일이었다. 스탠포드는 다시 한번 가능성을 인정했다. 그것은 구글을 그들의 서버에서 밀어내지 않았다. 대신, 스탠포드의 자문 위원들은 페이지와 브린을 상업적인 방향으로 밀어붙였다.

처음에, 설립자들은 그들의 알고리즘을 다른 검색 엔진에 판매하거나 라이선스하려고 했다. 그들은 야후, 인포섹, 익사이트와 미팅을 가졌다. 아무도 그 값을 볼 수 없었다. 그들은 포탈에 집중했다. 곧 황당하게 들릴 움직임으로, 그들은 각각 구글을 백만 달러 이하로 살 기회를 놓쳤고, 페이지와 브린은 그들의 비전을 알아주는 파트너를 찾을 수 없었다.

스탠포드 대학의 한 교직원은 제프 베이조스와 데이비드 체리턴을 포함한 몇몇 투자자들과 그들을 연결시킬 수 있었다. 1998년 9월에 정식으로 법인화하여 친구의 차고로 이전하였고, 기호학 시스템 동문 마리사 메이어를 포함한 몇몇 초기 직원들을 데리고 왔다.

![image](https://i1.wp.com/css-tricks.com/wp-content/uploads/2020/09/page-brin.jpg?resize=725%2C381&ssl=1)

백만 달러의 투자에도 불구하고, 구글 창업자들은 검소함, 단순함, 신속함이라는 철학을 고수했다. 투자자들의 이따금 독촉에도 불구하고, 그들은 포털 전략에 저항하고 검색에 집중했다. 그들은 계속해서 알고리즘을 조정하고 결과의 정확성에 대해 연구했다. 그들은 기계에 집중했다. 그들은 누군가가 검색한 단어를 실제로 의미 있는 것으로 바꾸기를 원했다. 상위 3개 결과에서 찾고 있던 것을 찾을 수 없다면 구글은 실패했을 것이다.

구글은 언론에서 과장된 광고와 긍정적인 입소문이 뒤따랐다. Steven Levy는 Newsweek에 기고한 글에서 "Delphi의 Oracle의 첨단 기술 버전으로, 가장 난해한 질문에 대한 모든 사람들의 대답에서 마우스 클릭 한 번으로 떨어뜨리고, 간단한 답변을 매우 효율적으로 전달하여 그 과정에 중독성이 생겼다"고 설명했다. 검색과 동의어인 사이트의 동사 형태인 "구글링"이 일반적인 국어로 들어간 것은 이 무렵이다. 포털 전쟁은 여전히 계속되고 있었지만, 구글은 소음에 대한 침착하고 정확한 대안으로 고개를 들고 있었다.

1998년 말, 그들은 하루에 10,000건의 검색을 제공했습니다. 1년 후, 그것은 하루에 7백만 개로 급증할 것이다. 그러나 조용히, 막후에서, 그들은 제국의 조각들을 조립하기 시작했다.

웹이 성장함에 따라, 기술자들과 언론인들은 구글의 종말을 예측했습니다; 그들은 결코 따라갈 수 없을 것입니다. 하지만 그들은 죽어가고 있는 경쟁자 명단보다 더 오래 살아남았다. 2001년, 익사이트는 파산했고, 라이코스는 문을 닫았고, 디즈니는 인포섹을 중단했다. 구글이 올라와서 그들을 대체했다. 2006년이 되어서야 구글이 야후를 제치고 1위 웹사이트가 될 것이다. 하지만 그때쯤이면 그 회사는 완전히 다른 무언가로 변모하게 될 것입니다.

1999년에 또 다른 투자처를 확보한 후, 구글은 새로운 본사로 이전했고, 새로운 직원들로 구성된 군대를 소집했다. 신입사원 명단에는 AltaVista의 전직 엔지니어들과 대표적인 인공지능 전문가인 Peter Norvig가 포함되었다. 구글은 전례 없이 기술 발전에 초점을 맞췄다. 더 나은 서버. 거미 속도가 빨라집니다. 더 큰 인덱스. 구글 내부의 엔지니어들은 이론적인 것에 불과한 웹 인프라를 발명했습니다.

그들은 새로운 것들과 새로운 제품들에 대해 그들의 기계를 훈련시켰다. 그러나 애플리케이션, 번역, 이메일, 클릭당 결제 광고에 관계없이, 그들은 같은 전제하에 휴식을 취했다. 기계는 인간의 지능을 증가시키고 재상상할 수 있습니다. 그리고 무한한 규모로 그것을 할 수 있습니다. 구글은 인공지능의 가치 제안을 받아들여 이를 주류로 끌어올렸다.

![image](https://i0.wp.com/css-tricks.com/wp-content/uploads/2020/09/page-brin-schmidt.jpeg?resize=474%2C266&ssl=1)

2001년, 페이지와 브린은 실리콘 밸리의 베테랑 에릭 슈미트를 그들의 CEO로 임명했다. 그는 10년 동안 그가 차지했던 역할이다. 그는 가장 큰 성장과 혁신의 시기에 그 회사를 감독할 것이다. 구글 직원 4번 헤더 케언스는 입사 첫날을 회상한다. "그는 이 회사와 이런 식의 공개 연설을 했고 그는 `당신의 진짜 경쟁자가 누구인지 알아줬으면 좋겠다`고 말했습니다." 그는 `마이크로소프트`라고 말했다. 다들 갔지 뭐야?“

빌 게이츠는 나중에 "검색 엔진 사업에서 구글은 초기 혁신자들을 날려버리고, 그들을 날려버렸다"고 말하곤 했다. 구글과 마이크로소프트가 맞붙는 시대가 올 것이다. 에릭 슈미트는 구글이 어디로 가고 있는지에 대해 옳았다. 하지만 마이크로소프트가 구글을 위협으로 인식하려면 몇 년이 걸릴 것이다. 1990년대 후반, 그들은 디지털 세계를 휩쓸었던 또 다른 실리콘 밸리의 신생 기업을 백미러로 보느라 너무 바빴다. 넷스케이프와의 전쟁이 다가오고 있는 마이크로소프트는 5년 이상 웹을 계속 사용하게 될 것이다.